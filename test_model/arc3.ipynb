{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "usage: ipykernel_launcher.py [-h] [-d DEVICE] [-m MODEL] [-q]\nipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\bawanag\\AppData\\Roaming\\jupyter\\runtime\\kernel-3aeabc46-111f-4c69-9a84-e86e402fd2ce.json\n"
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from  torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-d','--device', default='cuda', type=str,\n",
    "                    help='test device cuda or cpu(default: cuda)')\n",
    "parser.add_argument('-m', '--model', default='resnet/resnet18.pth', type=str,\n",
    "                    help='path of test model (default: resnet/resnet18.pth)')\n",
    "parser.add_argument('-q', '--quantization', action='store_true',  help='disables CUDA training')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# from torchsummary import summary\n",
    "starttime = datetime.datetime.now()\n",
    "device = torch.device(args.device)\n",
    "if True == args.quantization :\n",
    "    model = torch.jit.load(args.model).to(device)\n",
    "else :\n",
    "    model = torch.load(args.model).to(device)\n",
    "\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model = torch.load('xception.pth').to(device)\n",
    "# model = torch.load('densenet201.pth').to(device)\n",
    "# model = torch.load('vgg11_pruning_fc.pth').to(device)\n",
    "\n",
    "# model = torch.load('vgg/vgg11.pth').to(device)\n",
    "# model = torch.load('vgg/vgg11_bn.pth').to(device)\n",
    "# model = torch.load('vgg/vgg13.pth').to(device)\n",
    "# model = torch.load('vgg/vgg13_bn.pth').to(device)\n",
    "# model = torch.load('vgg/vgg16.pth').to(device)\n",
    "# model = torch.load('vgg/vgg16_bn.pth').to(device)\n",
    "# model = torch.load('vgg/vgg19.pth').to(device)\n",
    "# model = torch.load('vgg/vgg19_bn.pth').to(device)\n",
    "\n",
    "# model = torch.load('resnet/resnet18_pruning.pth').to(device)\n",
    "# model = torch.load('resnet/resnet18.pth').to(device)\n",
    "# model = torch.load('resnet/resnet34.pth').to(device)\n",
    "# model = torch.load('resnet/resnet50.pth').to(device)\n",
    "# model = torch.load('resnet/resnet101.pth').to(device)\n",
    "# model = torch.load('resnet/resnet152.pth').to(device)\n",
    "# model = torch.load('inception_v3/inception_v3.pth').to(device)\n",
    "\n",
    "\n",
    "# model = torch.jit.load('resnet/quantization/resnet18.pth').to(device)\n",
    "# model = torch.jit.load('resnet/quantization/resnext101_32x8d.pth').to(device)\n",
    "# model = torch.jit.load('quantization_models/mobilenet_v2.pth').to(device)\n",
    "# model = torch.jit.load('quantization_models/inception_v3.pth').to(device)\n",
    "\n",
    "\n",
    "# model_name = 'inception_v3'\n",
    "# model = models.quantization.__dict__[model_name](pretrained=True,progress=True,quantize=True).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-be46cb14ad82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclass_to_lable_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mclass_to_lable_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_to_lable_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_to_lable_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mclass_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_to_lable_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "root_dir = \"../../my_imagenet/ImageNet_validset/\"#identify the classification \n",
    "class_label_location = \"../../my_imagenet/scrip/imagenet_class_index.txt\"\n",
    "class_names = []\n",
    "with open(class_label_location) as f:\n",
    "    lines=f.readlines()\n",
    "    class_to_lable_json = lines[0]\n",
    "    class_to_lable_dict = json.loads(s=class_to_lable_json)\n",
    "    for key in class_to_lable_dict:\n",
    "        class_names.append(class_to_lable_dict[key][0])\n",
    "        \n",
    "def get_class_from_path(value):\n",
    "    for key in class_to_lable_dict:\n",
    "        if value == class_to_lable_dict[key][0]:\n",
    "            return int(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(root_dir, dirs):\n",
    "    \"\"\" Fetches the meta data for all the images and assigns labels.\n",
    "    \"\"\"\n",
    "    paths, classes = [], []\n",
    "    for i, dir_ in enumerate(dirs):\n",
    "        for entry in os.scandir(root_dir + dir_):\n",
    "            if (entry.is_file()):\n",
    "                paths.append(entry.path)\n",
    "                classes.append(get_class_from_path(dir_))\n",
    "                \n",
    "    return paths, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign images we will assign class 0, and malignant as 1\n",
    "paths, classes = get_meta(root_dir, class_names)\n",
    "\n",
    "data = {\n",
    "    'path': paths,\n",
    "    'class': classes\n",
    "}\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['path', 'class'])\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True) # Shuffles the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25777\n                                                path  class\n0  my_imagenet/ImageNet_validset/n03535780/ILSVRC...    602\n1  my_imagenet/ImageNet_validset/n03720891/ILSVRC...    641\n2  my_imagenet/ImageNet_validset/n02977058/ILSVRC...    480\n3  my_imagenet/ImageNet_validset/n02088364/ILSVRC...    162\n4  my_imagenet/ImageNet_validset/n02002556/ILSVRC...    127\n"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "log_time = 100\n",
    "validset_size = len(data_df)\n",
    "print(len(data_df))\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNet10(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load image from path and get label\n",
    "        x = Image.open(self.df['path'][index])\n",
    "        try:\n",
    "          x = x.convert('RGB') # To deal with some grayscale images in the data\n",
    "        except:\n",
    "          pass\n",
    "        y = torch.tensor(int(self.df['class'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "ins_dataset_valid = ImageNet10(\n",
    "#     df=data_df[0:int(len(data_df)/10)],\n",
    "    df=data_df,\n",
    "    transform=data_transform,\n",
    ")\n",
    "valid_dataset_loader = torch.utils.data.DataLoader(\n",
    "    ins_dataset_valid,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_valid_dataset_gpu():\n",
    "    print('=====================================================================')\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc1 = []\n",
    "    acc5 = []\n",
    "    with torch.no_grad():  \n",
    "        for i, data in enumerate(valid_dataset_loader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if i == 0 :\n",
    "                starttime_each_log = datetime.datetime.now()\n",
    "                print('Model inference time: {}'.format(starttime_each_log - starttime))\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            #             _, predicted = torch.max(outputs.data, 1)\n",
    "            #             total += labels.size(0)\n",
    "            #             total += len(labels)\n",
    "            #             correct += (predicted == labels).sum().item()\n",
    "            acc1_temp, acc5_temp = accuracy(outputs, labels, topk=(1, 5))\n",
    "\n",
    "            acc1.append(acc1_temp)\n",
    "            acc5.append(acc5_temp)\n",
    "            if i%log_time == 0 and i != 0:\n",
    "                endtime_each_log = datetime.datetime.now()\n",
    "                time_comsumption = endtime_each_log - starttime_each_log\n",
    "                starttime_each_log = endtime_each_log\n",
    "                print('validset    Loss: {:.4f}   Top1 Accuracy : {:.4f}%  Top5 accuracy : {:.4f}%  Time comsumption:{}'.format(running_loss/(i*batch_size), acc1_temp.item(), acc5_temp.item(), time_comsumption)) \n",
    "    print(\"===========================================================================\")\n",
    "    acc1_sum = 0\n",
    "    for acc1_temp in acc1:\n",
    "        acc1_sum += acc1_temp\n",
    "    acc1_average = acc1_sum/len(acc1)\n",
    "    acc5_sum = 0\n",
    "    for acc5_temp in acc5:\n",
    "        acc5_sum += acc5_temp\n",
    "    acc5_average = acc5_sum/len(acc5)\n",
    "    print('overall validset    Loss: {:.4f}   Top1 Accuracy : {:.4f}%  Top5 accuracy : {:.4f}% Time comsumption:{}'.format(running_loss/(i*batch_size), acc1_average.item(), acc5_average.item(), (datetime.datetime.now() - starttime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 128, 128]           9,408\n       BatchNorm2d-2         [-1, 64, 128, 128]             128\n              ReLU-3         [-1, 64, 128, 128]               0\n         MaxPool2d-4           [-1, 64, 64, 64]               0\n            Conv2d-5           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-6           [-1, 64, 64, 64]             128\n              ReLU-7           [-1, 64, 64, 64]               0\n            Conv2d-8           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-9           [-1, 64, 64, 64]             128\n             ReLU-10           [-1, 64, 64, 64]               0\n       BasicBlock-11           [-1, 64, 64, 64]               0\n           Conv2d-12           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-13           [-1, 64, 64, 64]             128\n             ReLU-14           [-1, 64, 64, 64]               0\n           Conv2d-15           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-16           [-1, 64, 64, 64]             128\n             ReLU-17           [-1, 64, 64, 64]               0\n       BasicBlock-18           [-1, 64, 64, 64]               0\n           Conv2d-19          [-1, 128, 32, 32]          73,728\n      BatchNorm2d-20          [-1, 128, 32, 32]             256\n             ReLU-21          [-1, 128, 32, 32]               0\n           Conv2d-22          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-23          [-1, 128, 32, 32]             256\n           Conv2d-24          [-1, 128, 32, 32]           8,192\n      BatchNorm2d-25          [-1, 128, 32, 32]             256\n             ReLU-26          [-1, 128, 32, 32]               0\n       BasicBlock-27          [-1, 128, 32, 32]               0\n           Conv2d-28          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-29          [-1, 128, 32, 32]             256\n             ReLU-30          [-1, 128, 32, 32]               0\n           Conv2d-31          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-32          [-1, 128, 32, 32]             256\n             ReLU-33          [-1, 128, 32, 32]               0\n       BasicBlock-34          [-1, 128, 32, 32]               0\n           Conv2d-35          [-1, 256, 16, 16]         294,912\n      BatchNorm2d-36          [-1, 256, 16, 16]             512\n             ReLU-37          [-1, 256, 16, 16]               0\n           Conv2d-38          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-39          [-1, 256, 16, 16]             512\n           Conv2d-40          [-1, 256, 16, 16]          32,768\n      BatchNorm2d-41          [-1, 256, 16, 16]             512\n             ReLU-42          [-1, 256, 16, 16]               0\n       BasicBlock-43          [-1, 256, 16, 16]               0\n           Conv2d-44          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-45          [-1, 256, 16, 16]             512\n             ReLU-46          [-1, 256, 16, 16]               0\n           Conv2d-47          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-48          [-1, 256, 16, 16]             512\n             ReLU-49          [-1, 256, 16, 16]               0\n       BasicBlock-50          [-1, 256, 16, 16]               0\n           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n             ReLU-53            [-1, 512, 8, 8]               0\n           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n           Conv2d-56            [-1, 512, 8, 8]         131,072\n      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n             ReLU-58            [-1, 512, 8, 8]               0\n       BasicBlock-59            [-1, 512, 8, 8]               0\n           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n             ReLU-62            [-1, 512, 8, 8]               0\n           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n             ReLU-65            [-1, 512, 8, 8]               0\n       BasicBlock-66            [-1, 512, 8, 8]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n           Linear-68                 [-1, 1000]         513,000\n================================================================\nTotal params: 11,689,512\nTrainable params: 11,689,512\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 82.01\nParams size (MB): 44.59\nEstimated Total Size (MB): 127.35\n----------------------------------------------------------------\n=====================================================================\nModel inference time: 0:00:03.924953\nvalidset    Loss: 0.0370   Top1 Accuracy : 65.6250%  Top5 accuracy : 87.5000%  Time comsumption:0:00:18.891336\nvalidset    Loss: 0.0385   Top1 Accuracy : 75.0000%  Top5 accuracy : 87.5000%  Time comsumption:0:00:17.859221\nvalidset    Loss: 0.0387   Top1 Accuracy : 71.8750%  Top5 accuracy : 90.6250%  Time comsumption:0:00:19.030220\nvalidset    Loss: 0.0389   Top1 Accuracy : 62.5000%  Top5 accuracy : 93.7500%  Time comsumption:0:00:17.639748\nvalidset    Loss: 0.0386   Top1 Accuracy : 87.5000%  Top5 accuracy : 100.0000%  Time comsumption:0:00:18.531483\nvalidset    Loss: 0.0386   Top1 Accuracy : 68.7500%  Top5 accuracy : 90.6250%  Time comsumption:0:00:17.479213\nvalidset    Loss: 0.0389   Top1 Accuracy : 84.3750%  Top5 accuracy : 96.8750%  Time comsumption:0:00:18.553628\nvalidset    Loss: 0.0388   Top1 Accuracy : 71.8750%  Top5 accuracy : 90.6250%  Time comsumption:0:00:18.541570\n===========================================================================\noverall validset    Loss: 0.0389   Top1 Accuracy : 69.8621%  Top5 accuracy : 89.1501% Time comsumption:0:02:31.298150\n"
    }
   ],
   "source": [
    "single_valid_dataset_gpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
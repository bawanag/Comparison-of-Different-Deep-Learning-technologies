{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bawanag/Document/software/anaconda/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/bawanag/Document/software/anaconda/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/bawanag/Document/software/anaconda/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/bawanag/Document/software/anaconda/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "             ReLU-17           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "             ReLU-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
      "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
      "             ReLU-26            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
      "             ReLU-37            [-1, 256, 4, 4]               0\n",
      "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
      "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
      "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
      "             ReLU-46            [-1, 256, 4, 4]               0\n",
      "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
      "             ReLU-49            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-53            [-1, 512, 2, 2]               0\n",
      "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-58            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-65            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.14\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 49.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torch_pruning as pruning\n",
    "from torchsummary import summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.load('resnet/resnet18.pth').to(device)\n",
    "# build layer dependency for resnet18\n",
    "model.eval()\n",
    "# prune.random_unstructured(model.conv1, name=\"weight\", amount=0.3)\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "             ReLU-17           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "             ReLU-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
      "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
      "             ReLU-26            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
      "             ReLU-37            [-1, 256, 4, 4]               0\n",
      "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
      "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
      "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
      "             ReLU-46            [-1, 256, 4, 4]               0\n",
      "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
      "             ReLU-49            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-53            [-1, 512, 2, 2]               0\n",
      "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-58            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-65            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.14\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 49.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.layer1[0].conv1, 'weight'),\n",
    "    (model.layer1[0].conv2, 'weight'),\n",
    "    (model.layer1[1].conv1, 'weight'),\n",
    "    (model.layer1[1].conv2, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in layer1[0].conv1: 27.68%\n",
      "Sparsity in layer1[0].conv2.weight: 17.69%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in layer1[0].conv1: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[0].conv1.weight == 0))\n",
    "        / float(model.layer1[0].conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in layer1[0].conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[0].conv2.weight == 0))\n",
    "        / float(model.layer1[0].conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "# print(\n",
    "#     \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "#         100. * float(torch.sum(model.fc1.weight == 0))\n",
    "#         / float(model.fc1.weight.nelement())\n",
    "#     )\n",
    "# )\n",
    "# print(\n",
    "#     \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "#         100. * float(torch.sum(model.fc2.weight == 0))\n",
    "#         / float(model.fc2.weight.nelement())\n",
    "#     )\n",
    "# )\n",
    "# print(\n",
    "#     \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "#         100. * float(torch.sum(model.fc3.weight == 0))\n",
    "#         / float(model.fc3.weight.nelement())\n",
    "#     )\n",
    "# )\n",
    "# print(\n",
    "#     \"Global sparsity: {:.2f}%\".format(\n",
    "#         100. * float(\n",
    "#             torch.sum(model.conv1.weight == 0)\n",
    "#             + torch.sum(model.conv2.weight == 0)\n",
    "#             + torch.sum(model.fc1.weight == 0)\n",
    "#             + torch.sum(model.fc2.weight == 0)\n",
    "#             + torch.sum(model.fc3.weight == 0)\n",
    "#         )\n",
    "#         / float(\n",
    "#             model.conv1.weight.nelement()\n",
    "#             + model.conv2.weight.nelement()\n",
    "#             + model.fc1.weight.nelement()\n",
    "#             + model.fc2.weight.nelement()\n",
    "#             + model.fc3.weight.nelement()\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
